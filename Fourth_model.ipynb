{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19134a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 1 - Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Poisson\n",
    "from statsmodels.genmod.families.family import Tweedie\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"=== Chargement des données ===\")\n",
    "    \n",
    "    # 1. Chargement des données d'entraînement et de test\n",
    "    print(\"\\nChargement des données principales:\")\n",
    "    train_features = pd.read_csv('data/train_input_Z61KlZo.csv', low_memory=False)\n",
    "    train_target = pd.read_csv('data/train_output_DzPxaPY.csv')\n",
    "    test_df = pd.read_csv('data/test_input_5qJzHrr.csv', low_memory=False)\n",
    "    \n",
    "    # 2. Chargement du format de soumission\n",
    "    print(\"\\nChargement du format de soumission:\")\n",
    "    submission_format = pd.read_csv('data/submission_csv_file_random_example_3fbDtrr (1).csv')\n",
    "    \n",
    "    # Vérification des colonnes du format de soumission\n",
    "    expected_cols = ['ID', 'FREQ', 'CM', 'ANNEE_ASSURANCE', 'CHARGE']\n",
    "    if not all(col in submission_format.columns for col in expected_cols):\n",
    "        raise ValueError(f\"Format de soumission incorrect. Colonnes attendues: {expected_cols}\")\n",
    "    \n",
    "    # 3. Gestion de la colonne ANNEE_ASSURANCE\n",
    "    if 'ANNEE_ASSURANCE' in train_features.columns:\n",
    "        train_features = train_features.drop('ANNEE_ASSURANCE', axis=1)\n",
    "    \n",
    "    # 4. Fusion des données train\n",
    "    train_df = pd.merge(train_features, train_target, on='ID', how='inner')\n",
    "    \n",
    "    # 5. Vérifications et statistiques\n",
    "    print(\"\\n=== Dimensions des données ===\")\n",
    "    print(f\"Train features initiales: {train_features.shape}\")\n",
    "    print(f\"Train target: {train_target.shape}\")\n",
    "    print(f\"Train après fusion: {train_df.shape}\")\n",
    "    print(f\"Test: {test_df.shape}\")\n",
    "    print(f\"Format soumission: {submission_format.shape}\")\n",
    "    \n",
    "    # 6. Vérification de la cohérence des IDs\n",
    "    test_ids = set(test_df['ID'])\n",
    "    submission_ids = set(submission_format['ID'])\n",
    "    \n",
    "    if test_ids != submission_ids:\n",
    "        print(\"\\nATTENTION: Différence entre les IDs de test et de soumission!\")\n",
    "        print(f\"IDs uniquement dans test: {len(test_ids - submission_ids)}\")\n",
    "        print(f\"IDs uniquement dans soumission: {len(submission_ids - test_ids)}\")\n",
    "    \n",
    "    # 7. Vérification des colonnes\n",
    "    train_cols = set(train_df.columns) - {'FREQ', 'CM', 'CHARGE', 'ID'}\n",
    "    test_cols = set(test_df.columns) - {'ID'}\n",
    "    \n",
    "    missing_cols = test_cols - train_cols\n",
    "    extra_cols = train_cols - test_cols\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"\\nColonnes manquantes dans train: {missing_cols}\")\n",
    "    if extra_cols:\n",
    "        print(f\"\\nColonnes supplémentaires dans train: {extra_cols}\")\n",
    "    \n",
    "    # 8. Vérification des types de données\n",
    "    print(\"\\nTypes de données dans train:\")\n",
    "    print(train_df.dtypes.value_counts())\n",
    "    \n",
    "    # 9. Création d'un template de soumission vide\n",
    "    submission_template = submission_format.copy()\n",
    "    submission_template[['FREQ', 'CM', 'CHARGE']] = 0\n",
    "    \n",
    "    return {\n",
    "        'train_df': train_df,\n",
    "        'test_df': test_df,\n",
    "        'submission_format': submission_format,\n",
    "        'submission_template': submission_template,\n",
    "        'stats': {\n",
    "            'train_shape': train_df.shape,\n",
    "            'test_shape': test_df.shape,\n",
    "            'submission_shape': submission_format.shape,\n",
    "            'n_features': len(train_cols),\n",
    "            'missing_cols': list(missing_cols),\n",
    "            'extra_cols': list(extra_cols)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécution du chargement\n",
    "data_results = load_data()\n",
    "\n",
    "# Récupération des DataFrames\n",
    "train_df = data_results['train_df']\n",
    "test_df = data_results['test_df']\n",
    "submission_template = data_results['submission_template']\n",
    "\n",
    "# Affichage des statistiques détaillées\n",
    "print(\"\\n=== Résumé du chargement ===\")\n",
    "stats = data_results['stats']\n",
    "print(f\"Nombre d'observations train: {stats['train_shape'][0]}\")\n",
    "print(f\"Nombre d'observations test: {stats['test_shape'][0]}\")\n",
    "print(f\"Nombre de features: {stats['n_features']}\")\n",
    "\n",
    "if stats['missing_cols']:\n",
    "    print(\"\\nAttention: colonnes manquantes dans train!\")\n",
    "    print(stats['missing_cols'])\n",
    "\n",
    "if stats['extra_cols']:\n",
    "    print(\"\\nColonnes supplémentaires dans train:\")\n",
    "    print(stats['extra_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06552b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Définition de tous les groupes de variables\n",
    "WEATHER_VARS = {\n",
    "    'temp_max': [col for col in train_df.columns if any(x in col.upper() for x in \n",
    "                 ['NBJTX', 'TX', 'TXMAX', 'TXAB']) and 'TMMAX' not in col.upper()],\n",
    "    \n",
    "    'temp_min': [col for col in train_df.columns if any(x in col.upper() for x in \n",
    "                 ['NBJTN', 'TN', 'TNMIN', 'TNAB']) and 'TMMIN' not in col.upper()],\n",
    "    \n",
    "    'temp_moy': [col for col in train_df.columns if any(x in col.upper() for x in \n",
    "                 ['TM', 'TMM', 'TMMAX', 'TMMIN'])],\n",
    "    \n",
    "    'temp_amplitude': [col for col in train_df.columns if 'TAMPLI' in col.upper()],\n",
    "    \n",
    "    'wind': [col for col in train_df.columns if any(x in col.upper() for x in \n",
    "             ['FF', 'FX'])],\n",
    "    \n",
    "    'rain': [col for col in train_df.columns if any(x in col.upper() for x in \n",
    "             ['RR', 'RRAB'])]\n",
    "}\n",
    "\n",
    "# Redéfinition des variables bâtiment et activité\n",
    "BUILDING_VARS = {\n",
    "    # Surfaces\n",
    "    'surface': [f'SURFACE{i}' for i in range(1, 22)],\n",
    "    \n",
    "    # Nombre de bâtiments (attention au NBBAT12 manquant)\n",
    "    'buildings': [f'NBBAT{i}' for i in range(1, 15) if i != 12],\n",
    "    \n",
    "    # Caractéristiques du bâtiment\n",
    "    'characteristics': [f'CARACT{i}' for i in range(1, 6)],\n",
    "    \n",
    "    # Types de bâtiment\n",
    "    'building_type': ['TYPBAT1', 'TYPBAT2', 'ADOSS'],\n",
    "    \n",
    "    # Hauteurs et données BDTOPO\n",
    "    'height': [\n",
    "        'HAUTEUR', 'HAUTEUR_MAX',\n",
    "        'BDTOPO_BAT_MAX_HAUTEUR', 'BDTOPO_BAT_MAX_HAUTEUR_MAX'\n",
    "    ]\n",
    "}\n",
    "\n",
    "ACTIVITY_VARS = {\n",
    "    # Multi-équipement\n",
    "    'equipment': [f'EQUIPEMENT{i}' for i in range(1, 8)],\n",
    "    \n",
    "    # Activité et vocation\n",
    "    'activity': [\n",
    "        'ACTIVIT2',     # Activité\n",
    "        'VOCATION',     # Vocation de l'entité professionnelle\n",
    "        'TYPERS'        # Type de personne\n",
    "    ],\n",
    "    \n",
    "    # Catégorie\n",
    "    'category': ['COEFASS'],  # Retrait des variables TAILLE qui sont dans INSURANCE_VARS\n",
    "    \n",
    "}\n",
    "\n",
    "INSURANCE_VARS = {\n",
    "    # Indicateurs de risque\n",
    "    'risk_indicators': [f'RISK{i}' for i in range(1, 14)],\n",
    "    \n",
    "    # Données de capitaux\n",
    "    'capital': [f'KAPITAL{i}' for i in range(1, 44)],\n",
    "    \n",
    "    # Dérogations tarifaires\n",
    "    'derogation': [f'DEROG{i}' for i in range(1, 17)],\n",
    "    \n",
    "    # Franchises et indemnisations\n",
    "    'contract_terms': {\n",
    "        'franchise': ['FRCH1', 'FRCH2'],\n",
    "        'indemnisation': ['INDEM1', 'INDEM2']\n",
    "    },\n",
    "    \n",
    "    # Données d'activité et taille\n",
    "    'business_profile': {\n",
    "        'chiffre_affaires': ['CA1', 'CA2', 'CA3'],\n",
    "        'taille_risque': [f'TAILLE{i}' for i in range(1, 5)]  # Gardé ici car lié au profil business\n",
    "    },\n",
    "    \n",
    "    # Historique et sinistralité\n",
    "    'history': [\n",
    "        'NBSINCONJ',     # Sinistralité conjoncturelle\n",
    "        'NBSINSTRT',     # Sinistralité longue période\n",
    "        'ANCIENNETE',    # Ancienneté du contrat\n",
    "        'DUREE_REQANEUF' # Durée\n",
    "    ],\n",
    "    \n",
    "    # Données temporelles\n",
    "    'time': [\n",
    "        'AN_EXERC',        # Année d'exercice\n",
    "        'ANNEE_ASSURANCE'  # Nombre d'années assurées\n",
    "    ]\n",
    "}\n",
    "GEOGRAPHIC_VARS = {\n",
    "    # Distances par type d'environnement\n",
    "    'distances': {\n",
    "        'urban': [  # Zones urbaines\n",
    "            'DISTANCE_111',  # Tissu urbain continu\n",
    "            'DISTANCE_112',  # Tissu urbain discontinu\n",
    "            'DISTANCE_121',  # Zones industrielles/commerciales\n",
    "            'DISTANCE_122',  # Réseaux routier/ferroviaire\n",
    "            'DISTANCE_123',  # Zones portuaires\n",
    "            'DISTANCE_124',  # Aéroports\n",
    "            'DISTANCE_131',  # Extraction de matériaux\n",
    "            'DISTANCE_132',  # Décharges\n",
    "            'DISTANCE_133',  # Chantiers\n",
    "            'DISTANCE_141',  # Espaces verts urbains\n",
    "            'DISTANCE_142'   # Équipements sportifs et de loisirs\n",
    "        ],\n",
    "        'natural': [  # Zones naturelles\n",
    "            'DISTANCE_311',  # Forêts de feuillus\n",
    "            'DISTANCE_312',  # Forêts de conifères\n",
    "            'DISTANCE_313',  # Forêts mélangées\n",
    "            'DISTANCE_321',  # Pelouses et pâturages naturels\n",
    "            'DISTANCE_322',  # Landes et broussailles\n",
    "            'DISTANCE_323',  # Végétation sclérophylle\n",
    "            'DISTANCE_324',  # Forêt et végétation arbustive en mutation\n",
    "            'DISTANCE_331',  # Plages, dunes et sable\n",
    "            'DISTANCE_332',  # Roches nues\n",
    "            'DISTANCE_333',  # Végétation clairsemée\n",
    "            'DISTANCE_334',  # Zones incendiées\n",
    "            'DISTANCE_335'   # Glaciers et neiges éternelles\n",
    "        ],\n",
    "        'water': [  # Zones aquatiques\n",
    "            'DISTANCE_411',  # Marais intérieurs\n",
    "            'DISTANCE_412',  # Tourbières\n",
    "            'DISTANCE_421',  # Marais maritimes\n",
    "            'DISTANCE_422',  # Marais salants\n",
    "            'DISTANCE_423',  # Zones intertidales\n",
    "            'DISTANCE_511',  # Cours d'eau\n",
    "            'DISTANCE_512',  # Plans d'eau\n",
    "            'DISTANCE_521',  # Lagunes littorales\n",
    "            'DISTANCE_522',  # Estuaires\n",
    "            'DISTANCE_523'   # Mers et océans\n",
    "        ],\n",
    "        'other': [  # Autres distances\n",
    "            'DISTANCE_211',  # Terres arables hors périmètres d'irrigation\n",
    "            'DISTANCE_212',  # Périmètres irrigués en permanence\n",
    "            'DISTANCE_213',  # Rizières\n",
    "            'DISTANCE_221',  # Vignobles\n",
    "            'DISTANCE_222',  # Vergers et petits fruits\n",
    "            'DISTANCE_223',  # Oliveraies\n",
    "            'DISTANCE_231',  # Prairies et autres surfaces toujours en herbe\n",
    "            'DISTANCE_242',  # Systèmes culturaux et parcellaires complexes\n",
    "            'DISTANCE_243',  # Surfaces agricoles avec végétation naturelle\n",
    "            'DISTANCE_244'   # Territoires agroforestiers\n",
    "        ],\n",
    "        'general': [  # Distances générales\n",
    "            'DISTANCE_1',    # Distance générale 1\n",
    "            'DISTANCE_2'     # Distance générale 2\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # Proportions par type d'environnement\n",
    "    'proportions': {\n",
    "        'urban': [  # Zones urbaines\n",
    "            'PROPORTION_11',  # Zones urbanisées\n",
    "            'PROPORTION_12',  # Zones industrielles et commerciales\n",
    "            'PROPORTION_13',  # Mines, décharges et chantiers\n",
    "            'PROPORTION_14'   # Espaces verts artificialisés\n",
    "        ],\n",
    "        'agricultural': [  # Zones agricoles\n",
    "            'PROPORTION_21',  # Terres arables\n",
    "            'PROPORTION_22',  # Cultures permanentes\n",
    "            'PROPORTION_23',  # Prairies\n",
    "            'PROPORTION_24'   # Zones agricoles hétérogènes\n",
    "        ],\n",
    "        'natural': [  # Zones naturelles\n",
    "            'PROPORTION_31',  # Forêts\n",
    "            'PROPORTION_32',  # Milieux à végétation arbustive et/ou herbacée\n",
    "            'PROPORTION_33'   # Espaces ouverts, sans ou avec peu de végétation\n",
    "        ],\n",
    "        'water': [  # Zones aquatiques\n",
    "            'PROPORTION_41',  # Zones humides intérieures\n",
    "            'PROPORTION_42',  # Zones humides maritimes\n",
    "            'PROPORTION_51',  # Eaux continentales\n",
    "            'PROPORTION_52'   # Eaux maritimes\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # Données d'altitude et zones\n",
    "    'topography': {\n",
    "        'altitude': [f'ALTITUDE_{i}' for i in range(1, 6)],  # Différents niveaux d'altitude\n",
    "        'zone_info': [\n",
    "            'ZONE',          # Zone géographique\n",
    "            'ZONE_VENT',     # Zone de vent\n",
    "            'ESPINSEE'       # Espace INSEE\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # Données d'urgence\n",
    "    'emergency': ['NB_CASERNES']  # Nombre de casernes de pompiers à proximité\n",
    "}\n",
    "DEMOGRAPHIC_VARS = {\n",
    "    # Variables ménages\n",
    "    'household': {\n",
    "        'general': ['MEN'],  # Nombre total de ménages\n",
    "        'composition': [\n",
    "            'MEN_1IND',      # Ménages d'un seul individu\n",
    "            'MEN_5IND',      # Ménages de 5 individus ou plus\n",
    "            'MEN_FMP'        # Ménages monoparentaux\n",
    "        ],\n",
    "        'housing_type': [\n",
    "            'MEN_COLL',      # Ménages en logements collectifs\n",
    "            'MEN_MAIS',      # Ménages en maison\n",
    "            'MEN_PROP'       # Ménages propriétaires\n",
    "        ],\n",
    "        'economic': [\n",
    "            'MEN_PAUV',      # Ménages pauvres\n",
    "            'MEN_SURF'       # Surface des logements du carreau\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # Variables logement\n",
    "    'housing': {\n",
    "        'construction_period': [\n",
    "            'LOG_AVA1',      # Avant année A1\n",
    "            'LOG_A1_A2',     # Entre A1 et A2\n",
    "            'LOG_A2_A3',     # Entre A2 et A3\n",
    "            'LOG_APA3'       # Après A3\n",
    "        ],\n",
    "        'special_categories': [\n",
    "            'LOG_INC',       # Date de construction inconnue\n",
    "            'LOG_SOC'        # Logements sociaux\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # Variables individus\n",
    "    'individual': {\n",
    "        'total': ['IND'],    # Nombre total d'individus\n",
    "        'age_groups': [\n",
    "            'IND_0_Y1',      # 0 à Y1 ans\n",
    "            'IND_Y1_Y2',     # Y1 à Y2 ans\n",
    "            'IND_Y2_Y3',     # Y2 à Y3 ans\n",
    "            'IND_Y3_Y4',     # Y3 à Y4 ans\n",
    "            'IND_Y4_Y5',     # Y4 à Y5 ans\n",
    "            'IND_Y5_Y6',     # Y5 à Y6 ans\n",
    "            'IND_Y6_Y7',     # Y6 à Y7 ans\n",
    "            'IND_Y7_Y8',     # Y7 à Y8 ans\n",
    "            'IND_Y8_Y9',     # Y8 à Y9 ans\n",
    "            'IND_Y9'         # Y9 ans ou plus\n",
    "        ],\n",
    "        'other': [\n",
    "            'IND_INC',       # Âge inconnu\n",
    "            'IND_SNV'        # Niveaux de vie winsorisés\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "TARGET_VARS = {\n",
    "    'primary': {\n",
    "        'frequency': ['FREQ'],      # Fréquence\n",
    "        'cost': ['CM'],            # Coût moyen\n",
    "        'total': ['CHARGE'],       # Charge totale\n",
    "        'period': ['ANNEE_ASSURANCE']  # Période d'assurance\n",
    "    },\n",
    "    'definitions': {\n",
    "        'FREQ': 'NOMBRE DE SINISTRES / ANNEE ASSURANCE',\n",
    "        'CM': 'CHARGE SINISTRES / NOMBRE DE SINISTRES',\n",
    "        'CHARGE': 'FREQ * CM * ANNEE_ASSURANCE',\n",
    "        'ANNEE_ASSURANCE': 'Durée de la période d\\'assurance en années'\n",
    "    }\n",
    "}\n",
    "ID_VARS = {\n",
    "    'identifiers': ['ID'],\n",
    "    'properties': {\n",
    "        'unique': True,          # L'ID doit être unique\n",
    "        'not_null': True,        # Pas de valeurs nulles autorisées\n",
    "        'type': 'str'           # Type attendu\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_weather_vars():\n",
    "    print(\"=== Vérification des variables météo ===\\n\")\n",
    "    \n",
    "    # 1. Vérifier les doublons globaux\n",
    "    all_weather_vars = []\n",
    "    for category, cols in WEATHER_VARS.items():\n",
    "        all_weather_vars.extend(cols)\n",
    "    \n",
    "    duplicates = [var for var in set(all_weather_vars) \n",
    "                 if all_weather_vars.count(var) > 1]\n",
    "    \n",
    "    if duplicates:\n",
    "        print(\"ATTENTION! Variables en double:\")\n",
    "        for var in duplicates:\n",
    "            categories = [cat for cat, cols in WEATHER_VARS.items() if var in cols]\n",
    "            print(f\"- {var} présent dans: {categories}\")\n",
    "    \n",
    "    # 2. Vérifier chaque catégorie\n",
    "    for category, cols in WEATHER_VARS.items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        print(f\"Nombre de variables: {len(cols)}\")\n",
    "        \n",
    "        # Vérifier les préfixes\n",
    "        prefixes = set([col.split('_')[0] for col in cols])\n",
    "        print(\"Préfixes trouvés:\", prefixes)\n",
    "        \n",
    "        # Exemples de variables\n",
    "        print(\"Exemples de variables:\", sorted(cols)[:3])\n",
    "        \n",
    "        # Vérifier l'existence dans le DataFrame\n",
    "        missing_in_df = [col for col in cols if col not in train_df.columns]\n",
    "        if missing_in_df:\n",
    "            print(f\"ATTENTION! Variables non trouvées dans le DataFrame:\")\n",
    "            print(missing_in_df)\n",
    "        \n",
    "        # Vérifier les valeurs manquantes\n",
    "        existing_cols = [col for col in cols if col in train_df.columns]\n",
    "        if existing_cols:\n",
    "            missing_pct = (train_df[existing_cols].isnull().mean() * 100).mean()\n",
    "            print(f\"Pourcentage moyen de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "    \n",
    "    # 3. Vérifier si des variables météo n'ont pas été classées\n",
    "    weather_patterns = {\n",
    "        'temp': ['TX', 'TN', 'TM', 'TEMP'],\n",
    "        'wind': ['FF', 'FX'],\n",
    "        'rain': ['RR', 'RRAB'],\n",
    "        'amplitude': ['TAMPLI']\n",
    "    }\n",
    "    \n",
    "    unclassified = []\n",
    "    for pattern_type, patterns in weather_patterns.items():\n",
    "        for col in train_df.columns:\n",
    "            if any(pattern in col.upper() for pattern in patterns):\n",
    "                if col not in all_weather_vars:\n",
    "                    unclassified.append((col, pattern_type))\n",
    "    \n",
    "    if unclassified:\n",
    "        print(\"\\nVariables météo potentiellement non classées:\")\n",
    "        for col, type_ in unclassified:\n",
    "            print(f\"- {col} (type: {type_})\")\n",
    "    \n",
    "    # 4. Résumé\n",
    "    print(\"\\n=== Résumé des variables météo ===\")\n",
    "    print(f\"Total variables classées: {len(set(all_weather_vars))}\")\n",
    "    print(f\"Variables en double: {len(duplicates)}\")\n",
    "    print(f\"Variables non classées: {len(unclassified)}\")\n",
    "    \n",
    "    return {\n",
    "        'classified_vars': set(all_weather_vars),\n",
    "        'duplicates': duplicates,\n",
    "        'unclassified': unclassified,\n",
    "        'missing_in_df': {cat: [col for col in cols if col not in train_df.columns] \n",
    "                         for cat, cols in WEATHER_VARS.items()}\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "weather_results = verify_weather_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_building_and_activity_vars():\n",
    "    print(\"=== Vérification des variables bâtiment et activité ===\\n\")\n",
    "    \n",
    "    # Collecter toutes les variables pour vérification des doublons\n",
    "    all_building_vars = []\n",
    "    all_activity_vars = []\n",
    "    \n",
    "    # Vérifier les deux groupes\n",
    "    for group_name, group_vars, all_vars_list in [\n",
    "        (\"BUILDING\", BUILDING_VARS, all_building_vars), \n",
    "        (\"ACTIVITY\", ACTIVITY_VARS, all_activity_vars)\n",
    "    ]:\n",
    "        print(f\"\\n{group_name}:\")\n",
    "        \n",
    "        for category, vars_list in group_vars.items():\n",
    "            print(f\"\\n  {category}:\")\n",
    "            print(f\"  Nombre de variables définies: {len(vars_list)}\")\n",
    "            print(\"  Variables:\", vars_list)\n",
    "            \n",
    "            # Vérifier l'existence\n",
    "            existing_vars = [var for var in vars_list if var in train_df.columns]\n",
    "            missing_vars = [var for var in vars_list if var not in train_df.columns]\n",
    "            \n",
    "            print(f\"  Variables trouvées: {len(existing_vars)}/{len(vars_list)}\")\n",
    "            \n",
    "            if missing_vars:\n",
    "                print(f\"  ATTENTION! Variables manquantes: {missing_vars}\")\n",
    "            \n",
    "            # Vérifier les valeurs manquantes pour les variables existantes\n",
    "            if existing_vars:\n",
    "                missing_pct = (train_df[existing_vars].isnull().mean() * 100).mean()\n",
    "                print(f\"  Pourcentage moyen de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "            \n",
    "            all_vars_list.extend(vars_list)\n",
    "    \n",
    "    # Vérifier les doublons entre les deux groupes\n",
    "    building_vars = set(all_building_vars)\n",
    "    activity_vars = set(all_activity_vars)\n",
    "    duplicates = building_vars.intersection(activity_vars)\n",
    "    \n",
    "    if duplicates:\n",
    "        print(\"\\nATTENTION! Variables en double entre BUILDING et ACTIVITY:\")\n",
    "        print(duplicates)\n",
    "    \n",
    "    # 3. Vérifier les variables non classées par type\n",
    "    patterns = {\n",
    "        'surface': 'SURFACE',\n",
    "        'batiment': 'NBBAT',\n",
    "        'caracteristique': 'CARACT',\n",
    "        'type_batiment': 'TYPBAT',\n",
    "        'hauteur': 'HAUTEUR',\n",
    "        'bdtopo': 'BDTOPO',\n",
    "        'equipement': 'EQUIPEMENT',\n",
    "        'activite': 'ACTIVIT',\n",
    "        'vocation': 'VOCATION',\n",
    "        'type_personne': 'TYPERS'\n",
    "    }\n",
    "    \n",
    "    unclassified = {}\n",
    "    all_defined_vars = building_vars.union(activity_vars)\n",
    "    \n",
    "    for pattern_name, pattern in patterns.items():\n",
    "        pattern_vars = [col for col in train_df.columns if pattern in col \n",
    "                       and col not in all_defined_vars]\n",
    "        if pattern_vars:\n",
    "            unclassified[pattern_name] = pattern_vars\n",
    "    \n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées par type:\")\n",
    "        for pattern_name, vars_list in unclassified.items():\n",
    "            print(f\"\\n{pattern_name.upper()}:\")\n",
    "            print(f\"Nombre: {len(vars_list)}\")\n",
    "            print(\"Variables:\", vars_list)\n",
    "    \n",
    "    # Résumé final\n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    \n",
    "    print(\"\\n=== Résumé ===\")\n",
    "    print(f\"Variables bâtiment: {len(building_vars)}\")\n",
    "    print(f\"Variables activité: {len(activity_vars)}\")\n",
    "    print(f\"Variables en double: {len(duplicates)}\")\n",
    "    print(f\"Variables non classées: {total_unclassified}\")\n",
    "    \n",
    "    return {\n",
    "        'building_vars': building_vars,\n",
    "        'activity_vars': activity_vars,\n",
    "        'duplicates': duplicates,\n",
    "        'unclassified': unclassified,\n",
    "        'stats': {\n",
    "            'building': {cat: len(vars_) for cat, vars_ in BUILDING_VARS.items()},\n",
    "            'activity': {cat: len(vars_) for cat, vars_ in ACTIVITY_VARS.items()},\n",
    "            'total_unclassified': total_unclassified\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "building_activity_results = verify_building_and_activity_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47696492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Pour les expressions régulières\n",
    "def verify_insurance_vars():\n",
    "    \"\"\"\n",
    "    Vérifie la cohérence et la présence des variables d'assurance.\n",
    "    \"\"\"\n",
    "    print(\"=== Vérification des variables d'assurance ===\\n\")\n",
    "    \n",
    "    # 1. Collecter toutes les variables définies\n",
    "    all_defined_vars = []\n",
    "    \n",
    "    # 2. Vérifier chaque catégorie principale\n",
    "    for category, content in INSURANCE_VARS.items():\n",
    "        # 2.1 Traitement des catégories avec sous-catégories\n",
    "        if isinstance(content, dict):\n",
    "            print(f\"\\n{category.upper()}:\")\n",
    "            for subcat, vars_list in content.items():\n",
    "                print(f\"\\n  {subcat}:\")\n",
    "                verify_variable_group(vars_list, all_defined_vars)\n",
    "        \n",
    "        # 2.2 Traitement des catégories simples\n",
    "        else:\n",
    "            print(f\"\\n{category.upper()}:\")\n",
    "            verify_variable_group(content, all_defined_vars)\n",
    "    \n",
    "    # 3. Vérifier les doublons\n",
    "    duplicates = find_duplicates(all_defined_vars)\n",
    "    \n",
    "    # 4. Vérifier les variables non classées\n",
    "    unclassified = find_unclassified_vars(all_defined_vars)\n",
    "    \n",
    "    # 5. Générer le résumé\n",
    "    print_summary(all_defined_vars, duplicates, unclassified)\n",
    "    \n",
    "    return generate_results(all_defined_vars, duplicates, unclassified)\n",
    "\n",
    "def verify_variable_group(vars_list, all_vars):\n",
    "    \"\"\"\n",
    "    Vérifie un groupe de variables et met à jour la liste globale.\n",
    "    \"\"\"\n",
    "    print(f\"  Nombre de variables définies: {len(vars_list)}\")\n",
    "    print(\"  Variables:\", vars_list)\n",
    "    \n",
    "    # Vérifier l'existence\n",
    "    existing_vars = [var for var in vars_list if var in train_df.columns]\n",
    "    missing_vars = [var for var in vars_list if var not in train_df.columns]\n",
    "    \n",
    "    print(f\"  Variables trouvées: {len(existing_vars)}/{len(vars_list)}\")\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"  ATTENTION! Variables manquantes: {missing_vars}\")\n",
    "    \n",
    "    # Vérifier les valeurs manquantes\n",
    "    if existing_vars:\n",
    "        missing_pct = (train_df[existing_vars].isnull().mean() * 100).mean()\n",
    "        print(f\"  Pourcentage moyen de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "    \n",
    "    all_vars.extend(vars_list)\n",
    "\n",
    "def find_duplicates(all_vars):\n",
    "    \"\"\"\n",
    "    Identifie les variables en double.\n",
    "    \"\"\"\n",
    "    return [var for var in set(all_vars) if all_vars.count(var) > 1]\n",
    "\n",
    "def find_unclassified_vars(all_vars):\n",
    "    \"\"\"\n",
    "    Identifie les variables d'assurance non classées.\n",
    "    \"\"\"\n",
    "    insurance_patterns = {\n",
    "        'risk': '^RISK[0-9]+$',\n",
    "        'capital': '^KAPITAL[0-9]+$',\n",
    "        'derogation': '^DEROG[0-9]+$',\n",
    "        'franchise': '^FRCH[0-9]+$',\n",
    "        'indemnisation': '^INDEM[0-9]+$',\n",
    "        'chiffre_affaires': '^CA[0-9]+$',\n",
    "        'sinistre': '^NBSIN',\n",
    "        'anciennete': '^ANCIEN',\n",
    "        'exercice': '^(AN_)?EXERC'\n",
    "    }\n",
    "    \n",
    "    # Exclure les patterns d'autres groupes\n",
    "    other_patterns = ['VOCATION', 'CARACT', 'NB_CASERNES', 'EQUIPEMENT', 'SURFACE']\n",
    "    \n",
    "    unclassified = {}\n",
    "    for pattern_name, pattern in insurance_patterns.items():\n",
    "        pattern_vars = [col for col in train_df.columns \n",
    "                       if re.match(pattern, col) and col not in all_vars\n",
    "                       and not any(other in col for other in other_patterns)]\n",
    "        if pattern_vars:\n",
    "            unclassified[pattern_name] = pattern_vars\n",
    "    \n",
    "    return {k: v for k, v in unclassified.items() if v}\n",
    "\n",
    "def print_summary(all_vars, duplicates, unclassified):\n",
    "    \"\"\"\n",
    "    Affiche le résumé de la vérification.\n",
    "    \"\"\"\n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées par type:\")\n",
    "        for pattern_name, vars_list in unclassified.items():\n",
    "            print(f\"\\n{pattern_name.upper()}:\")\n",
    "            print(f\"Nombre: {len(vars_list)}\")\n",
    "            print(\"Variables:\", vars_list)\n",
    "    \n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    \n",
    "    print(\"\\n=== Résumé ===\")\n",
    "    print(f\"Total variables définies: {len(all_vars)}\")\n",
    "    print(f\"Variables uniques: {len(set(all_vars))}\")\n",
    "    print(f\"Doublons: {len(duplicates)}\")\n",
    "    if duplicates:\n",
    "        print(\"Variables en double:\", duplicates)\n",
    "    print(f\"Variables non classées: {total_unclassified}\")\n",
    "\n",
    "def generate_results(all_vars, duplicates, unclassified):\n",
    "    \"\"\"\n",
    "    Génère le dictionnaire de résultats.\n",
    "    \"\"\"\n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    \n",
    "    return {\n",
    "        'all_vars': set(all_vars),\n",
    "        'duplicates': duplicates,\n",
    "        'unclassified': unclassified,\n",
    "        'missing_vars': {cat: [var for var in (content if isinstance(content, list) \n",
    "                                              else sum(content.values(), [])) \n",
    "                              if var not in train_df.columns] \n",
    "                        for cat, content in INSURANCE_VARS.items()},\n",
    "        'stats': {\n",
    "            'total_defined': len(all_vars),\n",
    "            'total_unique': len(set(all_vars)),\n",
    "            'total_duplicates': len(duplicates),\n",
    "            'total_unclassified': total_unclassified\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "insurance_results = verify_insurance_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06efc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_geographic_vars():\n",
    "    print(\"=== Vérification des variables géographiques ===\\n\")\n",
    "    \n",
    "    # Aplatir la structure imbriquée\n",
    "    all_vars = []\n",
    "    category_vars = {}  # Pour suivre les variables par catégorie\n",
    "    \n",
    "    # 1. Collecter toutes les variables\n",
    "    for main_category, content in GEOGRAPHIC_VARS.items():\n",
    "        category_vars[main_category] = []\n",
    "        if isinstance(content, dict):\n",
    "            for subcategory, vars_list in content.items():\n",
    "                all_vars.extend(vars_list)\n",
    "                category_vars[main_category].extend(vars_list)\n",
    "        else:\n",
    "            all_vars.extend(content)\n",
    "            category_vars[main_category].extend(content)\n",
    "    \n",
    "    # 2. Vérifier chaque catégorie\n",
    "    for main_category, content in GEOGRAPHIC_VARS.items():\n",
    "        print(f\"\\n{main_category.upper()}:\")\n",
    "        \n",
    "        if isinstance(content, dict):\n",
    "            for subcategory, vars_list in content.items():\n",
    "                print(f\"\\n  {subcategory}:\")\n",
    "                print(f\"  Nombre de variables définies: {len(vars_list)}\")\n",
    "                if len(vars_list) > 3:\n",
    "                    print(f\"  Exemples de variables: {vars_list[:3]} ...\")\n",
    "                else:\n",
    "                    print(f\"  Variables: {vars_list}\")\n",
    "                \n",
    "                # Vérifier l'existence\n",
    "                existing_vars = [var for var in vars_list if var in train_df.columns]\n",
    "                missing_vars = [var for var in vars_list if var not in train_df.columns]\n",
    "                \n",
    "                print(f\"  Variables trouvées: {len(existing_vars)}/{len(vars_list)}\")\n",
    "                \n",
    "                if missing_vars:\n",
    "                    print(f\"  ATTENTION! Variables manquantes ({len(missing_vars)}):\")\n",
    "                    for var in missing_vars[:5]:  # Montrer les 5 premiers exemples\n",
    "                        print(f\"    - {var}\")\n",
    "                    if len(missing_vars) > 5:\n",
    "                        print(f\"    ... et {len(missing_vars)-5} autres\")\n",
    "                \n",
    "                # Vérifier les valeurs manquantes\n",
    "                if existing_vars:\n",
    "                    missing_pct = (train_df[existing_vars].isnull().mean() * 100).mean()\n",
    "                    print(f\"  Pourcentage moyen de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "        else:\n",
    "            print(f\"Nombre de variables: {len(content)}\")\n",
    "            print(\"Variables:\", content)\n",
    "    \n",
    "    # 3. Vérifier les variables non classées\n",
    "    patterns = {\n",
    "        'distance': 'DISTANCE_',\n",
    "        'proportion': 'PROPORTION_',\n",
    "        'altitude': 'ALTITUDE_',\n",
    "        'zone': 'ZONE'\n",
    "    }\n",
    "    \n",
    "    unclassified = {}\n",
    "    for pattern_name, pattern in patterns.items():\n",
    "        pattern_vars = [col for col in train_df.columns if pattern in col \n",
    "                       and col not in all_vars]\n",
    "        if pattern_vars:\n",
    "            unclassified[pattern_name] = pattern_vars\n",
    "    \n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées par type:\")\n",
    "        for pattern_name, vars_list in unclassified.items():\n",
    "            print(f\"\\n{pattern_name.upper()}:\")\n",
    "            print(f\"Nombre: {len(vars_list)}\")\n",
    "            print(\"Exemples:\", vars_list[:5], \"...\" if len(vars_list) > 5 else \"\")\n",
    "    \n",
    "    # 4. Résumé final\n",
    "    print(\"\\n=== Résumé de la vérification géographique ===\")\n",
    "    print(f\"Total variables définies: {len(all_vars)}\")\n",
    "    \n",
    "    existing_total = len([var for var in all_vars if var in train_df.columns])\n",
    "    print(f\"Variables existantes: {existing_total}\")\n",
    "    print(f\"Variables manquantes: {len(all_vars) - existing_total}\")\n",
    "    \n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    print(f\"Variables non classées: {total_unclassified}\")\n",
    "    \n",
    "    # 5. Statistiques par catégorie\n",
    "    print(\"\\nStatistiques par catégorie principale:\")\n",
    "    for category, vars_list in category_vars.items():\n",
    "        existing = len([var for var in vars_list if var in train_df.columns])\n",
    "        print(f\"{category}: {existing}/{len(vars_list)} variables trouvées\")\n",
    "    \n",
    "    return {\n",
    "        'all_vars': set(all_vars),\n",
    "        'by_category': category_vars,\n",
    "        'unclassified': unclassified,\n",
    "        'stats': {\n",
    "            'total_defined': len(all_vars),\n",
    "            'total_existing': existing_total,\n",
    "            'total_missing': len(all_vars) - existing_total,\n",
    "            'total_unclassified': total_unclassified\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "geo_results = verify_geographic_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_demographic_vars():\n",
    "    print(\"=== Vérification des variables démographiques ===\\n\")\n",
    "    \n",
    "    # Aplatir la structure imbriquée\n",
    "    all_vars = []\n",
    "    for main_category, subcategories in DEMOGRAPHIC_VARS.items():\n",
    "        for subcat, vars_list in subcategories.items():\n",
    "            all_vars.extend(vars_list)\n",
    "    \n",
    "    # Vérifier chaque catégorie et sous-catégorie\n",
    "    for main_category, subcategories in DEMOGRAPHIC_VARS.items():\n",
    "        print(f\"\\n{main_category.upper()}:\")\n",
    "        \n",
    "        for subcat, vars_list in subcategories.items():\n",
    "            print(f\"\\n  {subcat}:\")\n",
    "            print(f\"  Nombre de variables définies: {len(vars_list)}\")\n",
    "            print(\"  Variables définies:\", vars_list)\n",
    "            \n",
    "            # Vérifier l'existence\n",
    "            existing_vars = [var for var in vars_list if var in train_df.columns]\n",
    "            missing_vars = [var for var in vars_list if var not in train_df.columns]\n",
    "            \n",
    "            print(f\"  Variables trouvées: {len(existing_vars)}/{len(vars_list)}\")\n",
    "            \n",
    "            if missing_vars:\n",
    "                print(f\"  ATTENTION! Variables manquantes: {missing_vars}\")\n",
    "            \n",
    "            # Vérifier les valeurs manquantes seulement pour les variables existantes\n",
    "            if existing_vars:\n",
    "                missing_pct = (train_df[existing_vars].isnull().mean() * 100).mean()\n",
    "                print(f\"  Pourcentage moyen de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "    \n",
    "    # Patterns pour identifier les variables démographiques\n",
    "    demo_patterns = {\n",
    "        'menage': '^MEN_',\n",
    "        'logement': '^LOG_',\n",
    "        'individu': '^IND_'\n",
    "    }\n",
    "    \n",
    "    # Exclure les patterns d'autres groupes\n",
    "    other_patterns = ['INDEM', 'EQUIPEMENT', 'ACTIVIT', 'SURFACE', 'CARACT']\n",
    "    \n",
    "    # Vérifier les variables non classées\n",
    "    unclassified = {}\n",
    "    for pattern_name, pattern in demo_patterns.items():\n",
    "        pattern_vars = [col for col in train_df.columns \n",
    "                       if re.match(pattern, col) \n",
    "                       and col not in all_vars\n",
    "                       and not any(other in col for other in other_patterns)]\n",
    "        if pattern_vars:\n",
    "            unclassified[pattern_name] = pattern_vars\n",
    "    \n",
    "    # Afficher les variables non classées par type\n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées par type:\")\n",
    "        for pattern_name, vars_list in unclassified.items():\n",
    "            if vars_list:  # N'afficher que si la liste n'est pas vide\n",
    "                print(f\"\\n{pattern_name.upper()}:\")\n",
    "                print(f\"Nombre: {len(vars_list)}\")\n",
    "                print(\"Variables:\", vars_list)\n",
    "    \n",
    "    # Résumé final\n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    \n",
    "    print(\"\\n=== Résumé de la vérification démographique ===\")\n",
    "    existing_vars = [var for var in all_vars if var in train_df.columns]\n",
    "    missing_vars = [var for var in all_vars if var not in train_df.columns]\n",
    "    print(f\"Variables définies: {len(all_vars)}\")\n",
    "    print(f\"Variables existantes: {len(existing_vars)}\")\n",
    "    print(f\"Variables manquantes: {len(missing_vars)}\")\n",
    "    print(f\"Variables non classées: {total_unclassified}\")\n",
    "    \n",
    "    return {\n",
    "        'all_defined_vars': all_vars,\n",
    "        'existing_vars': existing_vars,\n",
    "        'missing_vars': missing_vars,\n",
    "        'unclassified': unclassified,\n",
    "        'stats': {\n",
    "            'total_defined': len(all_vars),\n",
    "            'total_existing': len(existing_vars),\n",
    "            'total_missing': len(missing_vars),\n",
    "            'total_unclassified': total_unclassified\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "demo_results = verify_demographic_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c830eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_target_vars():\n",
    "    print(\"=== Vérification des variables cibles ===\\n\")\n",
    "    \n",
    "    # Aplatir la structure pour les variables\n",
    "    all_vars = []\n",
    "    for category in TARGET_VARS['primary'].values():\n",
    "        all_vars.extend(category)\n",
    "    \n",
    "    # Vérifier la présence des variables\n",
    "    for category, vars_list in TARGET_VARS['primary'].items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        print(f\"Variables: {vars_list}\")\n",
    "        \n",
    "        # Vérifier l'existence\n",
    "        missing = [var for var in vars_list if var not in train_df.columns]\n",
    "        if missing:\n",
    "            print(f\"ATTENTION! Variables manquantes: {missing}\")\n",
    "        \n",
    "        # Vérifier les valeurs manquantes\n",
    "        if vars_list:\n",
    "            missing_pct = (train_df[vars_list].isnull().mean() * 100).mean()\n",
    "            print(f\"Pourcentage moyen de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "        \n",
    "        # Afficher la définition\n",
    "        for var in vars_list:\n",
    "            if var in TARGET_VARS['definitions']:\n",
    "                print(f\"Définition de {var}: {TARGET_VARS['definitions'][var]}\")\n",
    "    \n",
    "    # Vérifier les variables non classées\n",
    "    target_patterns = {\n",
    "        'frequence': '^FREQ',\n",
    "        'cout_moyen': '^CM',\n",
    "        'charge': '^CHARGE',\n",
    "        'annee': '^ANNEE_ASSURANCE'\n",
    "    }\n",
    "    \n",
    "    # Exclure les patterns d'autres groupes\n",
    "    other_patterns = ['FRCH', 'CARACT', 'SURFACE']\n",
    "    \n",
    "    unclassified = {}\n",
    "    for pattern_name, pattern in target_patterns.items():\n",
    "        pattern_vars = [col for col in train_df.columns \n",
    "                       if re.match(pattern, col) \n",
    "                       and col not in all_vars\n",
    "                       and not any(other in col for other in other_patterns)]\n",
    "        if pattern_vars:\n",
    "            unclassified[pattern_name] = pattern_vars\n",
    "    \n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées par type:\")\n",
    "        for pattern_name, vars_list in unclassified.items():\n",
    "            if vars_list:\n",
    "                print(f\"\\n{pattern_name.upper()}:\")\n",
    "                print(f\"Nombre: {len(vars_list)}\")\n",
    "                print(\"Variables:\", vars_list)\n",
    "    \n",
    "    # Vérifier la cohérence des calculs\n",
    "    if all(var in train_df.columns for var in ['FREQ', 'CM', 'CHARGE', 'ANNEE_ASSURANCE']):\n",
    "        # Calculer CHARGE théorique\n",
    "        charge_calc = train_df['FREQ'] * train_df['CM'] * train_df['ANNEE_ASSURANCE']\n",
    "        \n",
    "        # Comparer avec CHARGE réelle\n",
    "        diff_pct = abs(charge_calc - train_df['CHARGE']).mean() / train_df['CHARGE'].mean() * 100\n",
    "        print(f\"\\nDifférence moyenne entre CHARGE calculée et réelle: {diff_pct:.2f}%\")\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    print(\"\\nStatistiques descriptives:\")\n",
    "    for var in all_vars:\n",
    "        if var in train_df.columns:\n",
    "            stats = train_df[var].describe()\n",
    "            print(f\"\\n{var}:\")\n",
    "            print(f\"  Min: {stats['min']:.2f}\")\n",
    "            print(f\"  Max: {stats['max']:.2f}\")\n",
    "            print(f\"  Moyenne: {stats['mean']:.2f}\")\n",
    "            print(f\"  Écart-type: {stats['std']:.2f}\")\n",
    "    \n",
    "    # Résumé final\n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    print(\"\\n=== Résumé ===\")\n",
    "    print(f\"Variables définies: {len(all_vars)}\")\n",
    "    print(f\"Variables existantes: {len([var for var in all_vars if var in train_df.columns])}\")\n",
    "    print(f\"Variables manquantes: {len([var for var in all_vars if var not in train_df.columns])}\")\n",
    "    print(f\"Variables non classées: {total_unclassified}\")\n",
    "    \n",
    "    return {\n",
    "        'variables': all_vars,\n",
    "        'definitions': TARGET_VARS['definitions'],\n",
    "        'unclassified': unclassified,\n",
    "        'missing_stats': {var: train_df[var].isnull().mean() * 100 \n",
    "                         for var in all_vars if var in train_df.columns},\n",
    "        'stats': {\n",
    "            'total_defined': len(all_vars),\n",
    "            'total_existing': len([var for var in all_vars if var in train_df.columns]),\n",
    "            'total_missing': len([var for var in all_vars if var not in train_df.columns]),\n",
    "            'total_unclassified': total_unclassified\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "target_results = verify_target_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ec3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_id_vars():\n",
    "    \"\"\"\n",
    "    Vérifie la cohérence et la présence des variables d'identification.\n",
    "    \"\"\"\n",
    "    print(\"=== Vérification des variables d'identification ===\\n\")\n",
    "    \n",
    "    id_vars = ID_VARS['identifiers']\n",
    "    properties = ID_VARS['properties']\n",
    "    \n",
    "    # 1. Vérifier la présence des variables\n",
    "    missing = [var for var in id_vars if var not in train_df.columns]\n",
    "    if missing:\n",
    "        print(f\"ATTENTION! Variables manquantes: {missing}\")\n",
    "        return\n",
    "    \n",
    "    # 2. Vérifier chaque identifiant\n",
    "    for id_var in id_vars:\n",
    "        verify_single_id(id_var, properties)\n",
    "    \n",
    "    # 3. Vérifier les variables non classées\n",
    "    unclassified = find_unclassified_vars(id_vars)\n",
    "    \n",
    "    # 4. Afficher les statistiques générales\n",
    "    print_id_statistics(id_vars)\n",
    "    \n",
    "    # 5. Générer et afficher le résumé final\n",
    "    results = generate_results(id_vars, unclassified)\n",
    "    print_final_summary(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def verify_single_id(id_var, properties):\n",
    "    \"\"\"Vérifie un identifiant spécifique.\"\"\"\n",
    "    print(f\"\\nVérification de {id_var}:\")\n",
    "    \n",
    "    # Vérifier l'unicité\n",
    "    if properties['unique']:\n",
    "        check_uniqueness(id_var)\n",
    "    \n",
    "    # Vérifier les valeurs nulles\n",
    "    if properties['not_null']:\n",
    "        check_null_values(id_var)\n",
    "    \n",
    "    # Vérifier le type de données\n",
    "    if properties['type'] == 'str':\n",
    "        check_data_type(id_var)\n",
    "    \n",
    "    # Vérifier la cohérence entre les ensembles\n",
    "    check_dataset_consistency(id_var)\n",
    "\n",
    "def check_uniqueness(id_var):\n",
    "    \"\"\"Vérifie l'unicité des identifiants.\"\"\"\n",
    "    n_unique = train_df[id_var].nunique()\n",
    "    n_total = len(train_df)\n",
    "    if n_unique != n_total:\n",
    "        print(f\"ATTENTION! {id_var} n'est pas unique:\")\n",
    "        print(f\"  {n_unique} valeurs uniques pour {n_total} lignes\")\n",
    "        duplicates = train_df[train_df[id_var].duplicated(keep=False)]\n",
    "        if not duplicates.empty:\n",
    "            print(\"  Exemples de doublons:\")\n",
    "            print(duplicates[id_var].head())\n",
    "\n",
    "def check_null_values(id_var):\n",
    "    \"\"\"Vérifie la présence de valeurs nulles.\"\"\"\n",
    "    n_null = train_df[id_var].isnull().sum()\n",
    "    if n_null > 0:\n",
    "        print(f\"ATTENTION! {n_null} valeurs nulles trouvées\")\n",
    "\n",
    "def check_data_type(id_var):\n",
    "    \"\"\"Vérifie le type de données.\"\"\"\n",
    "    if not pd.api.types.is_string_dtype(train_df[id_var]):\n",
    "        print(f\"ATTENTION! {id_var} n'est pas de type string\")\n",
    "        print(f\"Type actuel: {train_df[id_var].dtype}\")\n",
    "\n",
    "def check_dataset_consistency(id_var):\n",
    "    \"\"\"Vérifie la cohérence entre train, test et soumission.\"\"\"\n",
    "    train_ids = set(train_df[id_var])\n",
    "    test_ids = set(test_df[id_var])\n",
    "    submission_ids = set(data_results['submission_format'][id_var])\n",
    "    \n",
    "    # Vérifier l'intersection train/test\n",
    "    common_train_test = train_ids.intersection(test_ids)\n",
    "    if common_train_test:\n",
    "        print(f\"\\nATTENTION! IDs communs entre train et test: {len(common_train_test)}\")\n",
    "        print(\"Exemples:\", list(common_train_test)[:5])\n",
    "    \n",
    "    # Vérifier la cohérence test/soumission\n",
    "    check_submission_consistency(test_ids, submission_ids)\n",
    "    \n",
    "    return train_ids, test_ids, submission_ids, common_train_test\n",
    "\n",
    "def check_submission_consistency(test_ids, submission_ids):\n",
    "    \"\"\"Vérifie la cohérence avec le fichier de soumission.\"\"\"\n",
    "    missing_in_submission = test_ids - submission_ids\n",
    "    extra_in_submission = submission_ids - test_ids\n",
    "    if missing_in_submission or extra_in_submission:\n",
    "        print(\"\\nIncohérences entre test et soumission:\")\n",
    "        if missing_in_submission:\n",
    "            print(f\"IDs manquants dans soumission: {len(missing_in_submission)}\")\n",
    "        if extra_in_submission:\n",
    "            print(f\"IDs supplémentaires dans soumission: {len(extra_in_submission)}\")\n",
    "    return missing_in_submission, extra_in_submission\n",
    "\n",
    "def find_unclassified_vars(id_vars):\n",
    "    \"\"\"Identifie les variables d'identification non classées.\"\"\"\n",
    "    id_patterns = {\n",
    "        'identifiant': '^ID',\n",
    "        'reference': '^REF',\n",
    "        'numero': '^NUM'\n",
    "    }\n",
    "    \n",
    "    # Exclure les patterns d'autres groupes\n",
    "    other_patterns = ['INDEM', 'IND_', 'INDICE']\n",
    "    \n",
    "    unclassified = {}\n",
    "    for pattern_name, pattern in id_patterns.items():\n",
    "        pattern_vars = [col for col in train_df.columns \n",
    "                       if re.match(pattern, col) \n",
    "                       and col not in id_vars\n",
    "                       and not any(other in col for other in other_patterns)]\n",
    "        if pattern_vars:\n",
    "            unclassified[pattern_name] = pattern_vars\n",
    "    \n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées par type:\")\n",
    "        for pattern_name, vars_list in unclassified.items():\n",
    "            if vars_list:\n",
    "                print(f\"\\n{pattern_name.upper()}:\")\n",
    "                print(f\"Nombre: {len(vars_list)}\")\n",
    "                print(\"Variables:\", vars_list)\n",
    "    \n",
    "    return unclassified\n",
    "\n",
    "def print_id_statistics(id_vars):\n",
    "    \"\"\"Affiche les statistiques des identifiants.\"\"\"\n",
    "    print(\"\\n=== Statistiques des IDs ===\")\n",
    "    for id_var in id_vars:\n",
    "        print(f\"\\n{id_var}:\")\n",
    "        print(f\"Train: {train_df[id_var].nunique()} valeurs uniques\")\n",
    "        print(f\"Test: {test_df[id_var].nunique()} valeurs uniques\")\n",
    "        print(f\"Soumission: {data_results['submission_format'][id_var].nunique()} valeurs uniques\")\n",
    "        \n",
    "        if pd.api.types.is_string_dtype(train_df[id_var]):\n",
    "            train_lengths = train_df[id_var].str.len()\n",
    "            print(f\"Longueur min: {train_lengths.min()}\")\n",
    "            print(f\"Longueur max: {train_lengths.max()}\")\n",
    "            if train_lengths.min() != train_lengths.max():\n",
    "                print(\"ATTENTION! Longueurs variables\")\n",
    "\n",
    "def generate_results(id_vars, unclassified):\n",
    "    \"\"\"Génère le dictionnaire des résultats.\"\"\"\n",
    "    id_var = id_vars[0]  # Premier identifiant\n",
    "    train_ids = set(train_df[id_var])\n",
    "    test_ids = set(test_df[id_var])\n",
    "    submission_ids = set(data_results['submission_format'][id_var])\n",
    "    \n",
    "    total_unclassified = sum(len(vars_) for vars_ in unclassified.values())\n",
    "    \n",
    "    return {\n",
    "        'train_ids': train_ids,\n",
    "        'test_ids': test_ids,\n",
    "        'submission_ids': submission_ids,\n",
    "        'unclassified': unclassified,\n",
    "        'stats': {\n",
    "            'train_unique': len(train_ids),\n",
    "            'test_unique': len(test_ids),\n",
    "            'submission_unique': len(submission_ids),\n",
    "            'total_unclassified': total_unclassified\n",
    "        }\n",
    "    }\n",
    "\n",
    "def print_final_summary(results):\n",
    "    \"\"\"Affiche le résumé final.\"\"\"\n",
    "    print(\"\\n=== Résumé final ===\")\n",
    "    stats = results['stats']\n",
    "    print(f\"Train: {stats['train_unique']} IDs uniques\")\n",
    "    print(f\"Test: {stats['test_unique']} IDs uniques\")\n",
    "    print(f\"Soumission: {stats['submission_unique']} IDs uniques\")\n",
    "    print(f\"Variables non classées: {stats['total_unclassified']}\")\n",
    "\n",
    "# Exécuter la vérification\n",
    "id_results = verify_id_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea17ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_variable_classification():\n",
    "    print(\"=== Vérification globale de la classification des variables ===\")\n",
    "    \n",
    "    # 1. Collecter toutes les variables de chaque groupe\n",
    "    group_vars = {\n",
    "        'Weather': sum(WEATHER_VARS.values(), []),\n",
    "        'Building': sum(BUILDING_VARS.values(), []),\n",
    "        'Insurance': sum([v if isinstance(v, list) else sum(v.values(), []) \n",
    "                         for v in INSURANCE_VARS.values()], []),\n",
    "        'Geographic': sum([v if isinstance(v, list) else sum(v.values(), []) \n",
    "                          for v in GEOGRAPHIC_VARS.values()], []),\n",
    "        'Demographic': sum([sum(v.values(), []) for v in DEMOGRAPHIC_VARS.values()], []),\n",
    "        'Activity': sum(ACTIVITY_VARS.values(), []),\n",
    "        'Target': sum(TARGET_VARS['primary'].values(), []),\n",
    "        'ID': ID_VARS['identifiers']\n",
    "    }\n",
    "    \n",
    "    # 2. Vérifier les répétitions entre groupes\n",
    "    all_vars = set(train_df.columns)\n",
    "    classified_vars = set()\n",
    "    duplicates = {}\n",
    "    \n",
    "    for group, vars_list in group_vars.items():\n",
    "        # Vérifier les répétitions internes au groupe\n",
    "        internal_dupes = [v for v in vars_list if vars_list.count(v) > 1]\n",
    "        if internal_dupes:\n",
    "            print(f\"\\nRépétitions internes dans {group}:\")\n",
    "            print(set(internal_dupes))\n",
    "        \n",
    "        # Vérifier les répétitions avec d'autres groupes\n",
    "        for v in vars_list:\n",
    "            if v in classified_vars:\n",
    "                duplicates[v] = duplicates.get(v, []) + [group]\n",
    "            classified_vars.add(v)\n",
    "    \n",
    "    # 3. Identifier les variables non classées\n",
    "    unclassified = all_vars - classified_vars\n",
    "    \n",
    "    # 4. Afficher les résultats\n",
    "    print(\"\\n=== Résultats ===\")\n",
    "    print(f\"Total variables dans DataFrame: {len(all_vars)}\")\n",
    "    print(f\"Total variables classifiées: {len(classified_vars)}\")\n",
    "    print(f\"Variables non classées: {len(unclassified)}\")\n",
    "    \n",
    "    if duplicates:\n",
    "        print(\"\\nVariables présentes dans plusieurs groupes:\")\n",
    "        for var, groups in duplicates.items():\n",
    "            print(f\"- {var}: {groups}\")\n",
    "    \n",
    "    if unclassified:\n",
    "        print(\"\\nVariables non classées:\")\n",
    "        print(sorted(unclassified))\n",
    "    \n",
    "    return {\n",
    "        'group_stats': {group: len(vars_) for group, vars_ in group_vars.items()},\n",
    "        'duplicates': duplicates,\n",
    "        'unclassified': unclassified\n",
    "    }\n",
    "\n",
    "# Exécuter la vérification\n",
    "classification_results = verify_variable_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 1 : Fonction utilitaire\n",
    "def flatten_vars(var_dict):\n",
    "    \"\"\"\n",
    "    Aplatit un dictionnaire imbriqué de variables en une liste.\n",
    "    \"\"\"\n",
    "    flat_list = []\n",
    "    for k, v in var_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_v in v.values():\n",
    "                if isinstance(sub_v, list):\n",
    "                    flat_list.extend(sub_v)\n",
    "                elif isinstance(sub_v, dict):\n",
    "                    flat_list.extend(sum(sub_v.values(), []))\n",
    "        elif isinstance(v, list):\n",
    "            flat_list.extend(v)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 2 : Analyse initiale\n",
    "def analyze_missing_values(df):\n",
    "    \"\"\"\n",
    "    Analyse détaillée des valeurs manquantes par groupe et par tranche.\n",
    "    \"\"\"\n",
    "    groups = {\n",
    "        'Weather': sum(WEATHER_VARS.values(), []),\n",
    "        'Building': sum(BUILDING_VARS.values(), []),\n",
    "        'Activity': flatten_vars(ACTIVITY_VARS),\n",
    "        'Insurance': flatten_vars(INSURANCE_VARS),\n",
    "        'Geographic': flatten_vars(GEOGRAPHIC_VARS),\n",
    "        'Demographic': flatten_vars(DEMOGRAPHIC_VARS)\n",
    "    }\n",
    "    \n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing Count': df.isnull().sum(),\n",
    "        'Missing Percentage': df.isnull().sum() / len(df) * 100\n",
    "    }).sort_values('Missing Percentage', ascending=False)\n",
    "    \n",
    "    print_missing_analysis(df, missing_summary, groups)\n",
    "    \n",
    "    return missing_summary, groups\n",
    "\n",
    "def print_missing_analysis(df, missing_summary, groups):\n",
    "    \"\"\"Affiche l'analyse des valeurs manquantes\"\"\"\n",
    "    ranges = {\n",
    "        '0%': (0, 0),\n",
    "        '< 10%': (0, 10),\n",
    "        '10-30%': (10, 30),\n",
    "        '30-50%': (30, 50),\n",
    "        '50-70%': (50, 70),\n",
    "        '70-90%': (70, 90),\n",
    "        '> 90%': (90, 100)\n",
    "    }\n",
    "    \n",
    "    total_cols = 0\n",
    "    print(\"=== Analyse des valeurs manquantes par tranche ===\\n\")\n",
    "    \n",
    "    for range_name, (min_val, max_val) in ranges.items():\n",
    "        range_cols = missing_summary[\n",
    "            missing_summary['Missing Percentage'].between(min_val, max_val, inclusive='right' if range_name != '0%' else 'both')\n",
    "        ]\n",
    "        \n",
    "        n_cols = len(range_cols)\n",
    "        total_cols += n_cols\n",
    "        \n",
    "        if n_cols > 0:\n",
    "            print(f\"\\n=== Tranche {range_name} ({n_cols} colonnes) ===\")\n",
    "            for group_name, cols in groups.items():\n",
    "                group_cols = [col for col in range_cols.index if col in cols]\n",
    "                if group_cols:\n",
    "                    print(f\"\\n{group_name}: {len(group_cols)} colonnes\")\n",
    "                    print(f\"Variables: {group_cols}\")\n",
    "    \n",
    "    print(f\"\\nTotal des colonnes analysées: {total_cols}\")\n",
    "    print(f\"Nombre total de colonnes: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 3 : Préparation des données\n",
    "exclude_cols = ['FREQ', 'CM', 'CHARGE']\n",
    "X_train = train_df.drop(exclude_cols, axis=1)\n",
    "y_train = train_df[['FREQ', 'CM', 'CHARGE']]\n",
    "X_test = test_df.copy()\n",
    "\n",
    "# Analyse initiale\n",
    "missing_summary, groups = analyze_missing_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 4 : Traitement Weather\n",
    "def clean_weather_value(value):\n",
    "    \"\"\"\n",
    "    Nettoie une valeur météo en extrayant le nombre après '<=' ou '>='\n",
    "    Ex: '02. <= 65' -> 65\n",
    "    Ex: '04. >= 7' -> 7\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    try:\n",
    "        # Enlever le préfixe (ex: \"02. \")\n",
    "        value = value.split('.')[1].strip()\n",
    "        # Extraire le nombre après '<=' ou '>='\n",
    "        if '<=' in value:\n",
    "            return float(value.split('<=')[1].strip())\n",
    "        elif '>=' in value:\n",
    "            return float(value.split('>=')[1].strip())\n",
    "        return value\n",
    "    except:\n",
    "        return value\n",
    "\n",
    "def  clean_weather_vars(X_train, X_test, missing_summary, weather_cols):\n",
    "    \"\"\"\n",
    "    Traite les variables météo avec conversion des valeurs catégorielles en numériques\n",
    "    \"\"\"\n",
    "    missing_indicators = {}\n",
    "    print(\"\\nTraitement des variables météo:\")\n",
    "    \n",
    "    for col in weather_cols:\n",
    "        if col in X_train.columns:\n",
    "            missing_pct = missing_summary.loc[col, 'Missing Percentage']\n",
    "            print(f\"\\nColonne {col}:\")\n",
    "            print(f\"- Pourcentage de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "            print(f\"- Type initial: {X_train[col].dtype}\")\n",
    "            \n",
    "            # Afficher quelques valeurs avant conversion\n",
    "            if X_train[col].dtype == 'object':\n",
    "                print(\"- Exemples de valeurs avant conversion:\")\n",
    "                print(X_train[col].dropna().unique()[:5])\n",
    "            \n",
    "            # Créer indicateur de valeurs manquantes\n",
    "            if missing_pct > 0:\n",
    "                missing_indicators[f'{col}_is_missing'] = X_train[col].isnull().astype(int)\n",
    "            \n",
    "            if missing_pct <= 70:  # On traite uniquement si moins de 70% manquant\n",
    "                # Convertir les valeurs catégorielles en numériques\n",
    "                if X_train[col].dtype == 'object':\n",
    "                    print(\"- Conversion en numérique\")\n",
    "                    X_train[col] = X_train[col].apply(clean_weather_value)\n",
    "                    X_test[col] = X_test[col].apply(clean_weather_value)\n",
    "                    print(f\"- Type après conversion: {X_train[col].dtype}\")\n",
    "                \n",
    "                # Imputation avec la médiane\n",
    "                median_val = X_train[col].median()\n",
    "                X_train[col].fillna(median_val, inplace=True)\n",
    "                X_test[col].fillna(median_val, inplace=True)\n",
    "                print(f\"- Imputation avec la médiane: {median_val}\")\n",
    "                \n",
    "                # Vérification des valeurs uniques après traitement\n",
    "                unique_vals = sorted(X_train[col].unique())[:5]\n",
    "                print(f\"- Exemples de valeurs après traitement: {unique_vals}\")\n",
    "            else:\n",
    "                print(\"- Colonne ignorée (>70% manquant)\")\n",
    "    \n",
    "    return X_train, X_test, missing_indicators\n",
    "\n",
    "# Exécution\n",
    "X_train, X_test, weather_indicators = handle_weather_vars(\n",
    "    X_train, X_test, missing_summary, groups['Weather']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 5 : Traitement Building\n",
    "def handle_building_vars(X_train, X_test, missing_summary, building_cols):\n",
    "    \"\"\"\n",
    "    Traite les variables bâtiment avec vérification détaillée des types\n",
    "    \"\"\"\n",
    "    missing_indicators = {}\n",
    "    print(\"\\nTraitement des variables bâtiment:\")\n",
    "    \n",
    "    for col in building_cols:\n",
    "        if col in X_train.columns:\n",
    "            missing_pct = missing_summary.loc[col, 'Missing Percentage']\n",
    "            print(f\"\\nColonne {col}:\")\n",
    "            print(f\"- Pourcentage de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "            print(f\"- Type initial: {X_train[col].dtype}\")\n",
    "            \n",
    "            # Créer indicateur de valeurs manquantes\n",
    "            if missing_pct > 0:\n",
    "                missing_indicators[f'{col}_is_missing'] = X_train[col].isnull().astype(int)\n",
    "            \n",
    "            if missing_pct <= 70:  # On traite uniquement si moins de 70% manquant\n",
    "                if X_train[col].dtype in ['int64', 'float64']:\n",
    "                    # Pour les variables numériques\n",
    "                    median_val = X_train[col].median()\n",
    "                    X_train[col].fillna(median_val, inplace=True)\n",
    "                    X_test[col].fillna(median_val, inplace=True)\n",
    "                    print(f\"- Variable numérique, imputation avec la médiane: {median_val}\")\n",
    "                    print(f\"- Plage de valeurs: [{X_train[col].min()}, {X_train[col].max()}]\")\n",
    "                else:\n",
    "                    # Pour les variables catégorielles\n",
    "                    # Filtrer les valeurs non-nulles avant de les afficher\n",
    "                    unique_vals = X_train[col].dropna().unique()\n",
    "                    print(\"- Variable catégorielle, valeurs uniques:\")\n",
    "                    print(unique_vals[:5])\n",
    "                    \n",
    "                    # Si peu de valeurs uniques, on pourrait considérer une conversion en numérique\n",
    "                    if len(unique_vals) < 10:\n",
    "                        print(f\"- Nombre de catégories: {len(unique_vals)}\")\n",
    "                        print(\"- Distribution des valeurs:\")\n",
    "                        print(X_train[col].value_counts().head())\n",
    "                    \n",
    "                    mode_val = X_train[col].mode()[0]\n",
    "                    X_train[col].fillna('UNKNOWN', inplace=True)\n",
    "                    X_test[col].fillna('UNKNOWN', inplace=True)\n",
    "                    print(f\"- Imputation avec 'UNKNOWN'\")\n",
    "            else:\n",
    "                print(\"- Colonne ignorée (>70% manquant)\")\n",
    "            \n",
    "            # Vérification après traitement\n",
    "            missing_after = X_train[col].isnull().sum()\n",
    "            if missing_after > 0:\n",
    "                print(f\"⚠️ ATTENTION: {missing_after} valeurs manquantes restantes!\")\n",
    "    \n",
    "    return X_train, X_test, missing_indicators\n",
    "\n",
    "# Exécution\n",
    "X_train, X_test, building_indicators = handle_building_vars(\n",
    "    X_train, X_test, missing_summary, groups['Building']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaddb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 6 : Traitement Activity\n",
    "def handle_activity_vars(X_train, X_test, missing_summary, activity_cols):\n",
    "    \"\"\"\n",
    "    Traite les variables d'activité avec vérification détaillée des types et valeurs\n",
    "    \"\"\"\n",
    "    missing_indicators = {}\n",
    "    print(\"\\nTraitement des variables d'activité:\")\n",
    "    \n",
    "    for col in activity_cols:\n",
    "        if col in X_train.columns:\n",
    "            missing_pct = missing_summary.loc[col, 'Missing Percentage']\n",
    "            print(f\"\\nColonne {col}:\")\n",
    "            print(f\"- Pourcentage de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "            print(f\"- Type initial: {X_train[col].dtype}\")\n",
    "            \n",
    "            # Créer indicateur de valeurs manquantes\n",
    "            if missing_pct > 0:\n",
    "                missing_indicators[f'{col}_is_missing'] = X_train[col].isnull().astype(int)\n",
    "            \n",
    "            if missing_pct <= 70:  # On traite uniquement si moins de 70% manquant\n",
    "                if X_train[col].dtype in ['int64', 'float64']:\n",
    "                    # Pour les variables numériques\n",
    "                    median_val = X_train[col].median()\n",
    "                    X_train[col].fillna(median_val, inplace=True)\n",
    "                    X_test[col].fillna(median_val, inplace=True)\n",
    "                    print(f\"- Variable numérique, imputation avec la médiane: {median_val}\")\n",
    "                    print(f\"- Plage de valeurs: [{X_train[col].min()}, {X_train[col].max()}]\")\n",
    "                    print(f\"- Distribution: \\n{X_train[col].value_counts().head()}\")\n",
    "                else:\n",
    "                    # Pour les variables catégorielles\n",
    "                    unique_vals = X_train[col].unique()\n",
    "                    print(f\"- Variable catégorielle\")\n",
    "                    print(f\"- Nombre de catégories uniques: {len(unique_vals)}\")\n",
    "                    print(f\"- Top 5 catégories les plus fréquentes:\")\n",
    "                    print(X_train[col].value_counts().head())\n",
    "                    \n",
    "                    mode_val = X_train[col].mode()[0]\n",
    "                    X_train[col].fillna('UNKNOWN', inplace=True)\n",
    "                    X_test[col].fillna('UNKNOWN', inplace=True)\n",
    "                    print(f\"- Imputation avec 'UNKNOWN'\")\n",
    "            else:\n",
    "                print(\"- Colonne ignorée (>70% manquant)\")\n",
    "            \n",
    "            # Vérification après traitement\n",
    "            missing_after = X_train[col].isnull().sum()\n",
    "            if missing_after > 0:\n",
    "                print(f\"⚠️ ATTENTION: {missing_after} valeurs manquantes restantes!\")\n",
    "            \n",
    "            # Vérification de la cohérence entre train et test\n",
    "            train_unique = set(X_train[col].unique())\n",
    "            test_unique = set(X_test[col].unique())\n",
    "            diff_cats = test_unique - train_unique\n",
    "            if len(diff_cats) > 0:\n",
    "                print(f\"⚠️ ATTENTION: Catégories présentes dans test mais pas dans train: {diff_cats}\")\n",
    "    \n",
    "    return X_train, X_test, missing_indicators\n",
    "\n",
    "# Exécution\n",
    "X_train, X_test, activity_indicators = handle_activity_vars(\n",
    "    X_train, X_test, missing_summary, groups['Activity']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2794bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 7 : Traitement Insurance\n",
    "def handle_insurance_vars(X_train, X_test, missing_summary, insurance_cols):\n",
    "    \"\"\"\n",
    "    Traite les variables d'assurance avec vérification détaillée des types et valeurs\n",
    "    \"\"\"\n",
    "    missing_indicators = {}\n",
    "    print(\"\\nTraitement des variables d'assurance:\")\n",
    "    \n",
    "    for col in insurance_cols:\n",
    "        if col in X_train.columns:\n",
    "            missing_pct = missing_summary.loc[col, 'Missing Percentage']\n",
    "            print(f\"\\nColonne {col}:\")\n",
    "            print(f\"- Pourcentage de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "            print(f\"- Type initial: {X_train[col].dtype}\")\n",
    "            \n",
    "            # Créer indicateur de valeurs manquantes\n",
    "            if missing_pct > 0:\n",
    "                missing_indicators[f'{col}_is_missing'] = X_train[col].isnull().astype(int)\n",
    "            \n",
    "            if missing_pct <= 70:  # On traite uniquement si moins de 70% manquant\n",
    "                if X_train[col].dtype in ['int64', 'float64']:\n",
    "                    # Pour les variables numériques\n",
    "                    median_val = X_train[col].median()\n",
    "                    mean_val = X_train[col].mean()\n",
    "                    std_val = X_train[col].std()\n",
    "                    \n",
    "                    print(f\"- Variable numérique:\")\n",
    "                    print(f\"  * Médiane: {median_val}\")\n",
    "                    print(f\"  * Moyenne: {mean_val:.2f}\")\n",
    "                    print(f\"  * Écart-type: {std_val:.2f}\")\n",
    "                    print(f\"  * Plage: [{X_train[col].min()}, {X_train[col].max()}]\")\n",
    "                    \n",
    "                    # Détection des valeurs aberrantes\n",
    "                    outliers = X_train[col][(X_train[col] > mean_val + 3*std_val) | \n",
    "                                         (X_train[col] < mean_val - 3*std_val)].count()\n",
    "                    if outliers > 0:\n",
    "                        print(f\"⚠️ {outliers} valeurs aberrantes détectées (>3σ)\")\n",
    "                    \n",
    "                    X_train[col].fillna(median_val, inplace=True)\n",
    "                    X_test[col].fillna(median_val, inplace=True)\n",
    "                    \n",
    "                else:\n",
    "                    # Pour les variables catégorielles\n",
    "                    unique_vals = X_train[col].unique()\n",
    "                    print(f\"- Variable catégorielle:\")\n",
    "                    print(f\"  * Nombre de catégories: {len(unique_vals)}\")\n",
    "                    print(\"  * Distribution des valeurs:\")\n",
    "                    print(X_train[col].value_counts().head())\n",
    "                    \n",
    "                    # Si la variable a peu de catégories, on pourrait envisager un encodage\n",
    "                    if len(unique_vals) < 10:\n",
    "                        print(\"  * Candidat potentiel pour encodage catégoriel\")\n",
    "                    \n",
    "                    X_train[col].fillna('UNKNOWN', inplace=True)\n",
    "                    X_test[col].fillna('UNKNOWN', inplace=True)\n",
    "            else:\n",
    "                print(\"- Colonne ignorée (>70% manquant)\")\n",
    "            \n",
    "            # Vérifications post-traitement\n",
    "            missing_after = X_train[col].isnull().sum()\n",
    "            if missing_after > 0:\n",
    "                print(f\"⚠️ ATTENTION: {missing_after} valeurs manquantes restantes!\")\n",
    "            \n",
    "            # Vérification de la cohérence train/test\n",
    "            if X_train[col].dtype == 'object':\n",
    "                train_cats = set(X_train[col].unique())\n",
    "                test_cats = set(X_test[col].unique())\n",
    "                new_cats = test_cats - train_cats\n",
    "                if new_cats:\n",
    "                    print(f\"⚠️ Nouvelles catégories dans test: {new_cats}\")\n",
    "    \n",
    "    return X_train, X_test, missing_indicators\n",
    "\n",
    "# Exécution\n",
    "X_train, X_test, insurance_indicators = handle_insurance_vars(\n",
    "    X_train, X_test, missing_summary, groups['Insurance']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63555a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_geographic_vars(X_train, X_test, missing_summary, geographic_cols):\n",
    "    \"\"\"\n",
    "    Traite les variables géographiques avec vérification détaillée des types et valeurs\n",
    "    \"\"\"\n",
    "    missing_indicators = {}\n",
    "    print(\"\\nTraitement des variables géographiques:\")\n",
    "    \n",
    "    # Regrouper les colonnes par type\n",
    "    distance_cols = [col for col in geographic_cols if 'DISTANCE' in col]\n",
    "    proportion_cols = [col for col in geographic_cols if 'PROPORTION' in col]\n",
    "    altitude_cols = [col for col in geographic_cols if 'ALTITUDE' in col]\n",
    "    other_cols = [col for col in geographic_cols if col not in distance_cols + proportion_cols + altitude_cols]\n",
    "    \n",
    "    for col_type, cols in [\n",
    "        (\"Distance\", distance_cols),\n",
    "        (\"Proportion\", proportion_cols),\n",
    "        (\"Altitude\", altitude_cols),\n",
    "        (\"Autres\", other_cols)\n",
    "    ]:\n",
    "        print(f\"\\n=== Variables de {col_type} ===\")\n",
    "        \n",
    "        for col in cols:\n",
    "            if col in X_train.columns:\n",
    "                missing_pct = missing_summary.loc[col, 'Missing Percentage']\n",
    "                print(f\"\\nColonne {col}:\")\n",
    "                print(f\"- Pourcentage de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "                print(f\"- Type initial: {X_train[col].dtype}\")\n",
    "                \n",
    "                # Créer indicateur de valeurs manquantes\n",
    "                if missing_pct > 0:\n",
    "                    missing_indicators[f'{col}_is_missing'] = X_train[col].isnull().astype(int)\n",
    "                \n",
    "                if missing_pct <= 70:  # On traite uniquement si moins de 70% manquant\n",
    "                    if X_train[col].dtype in ['int64', 'float64']:\n",
    "                        # Pour les variables numériques\n",
    "                        stats = X_train[col].describe()\n",
    "                        print(\"- Statistiques descriptives:\")\n",
    "                        print(f\"  * Moyenne: {stats['mean']:.2f}\")\n",
    "                        print(f\"  * Écart-type: {stats['std']:.2f}\")\n",
    "                        print(f\"  * Min: {stats['min']:.2f}\")\n",
    "                        print(f\"  * 25%: {stats['25%']:.2f}\")\n",
    "                        print(f\"  * Médiane: {stats['50%']:.2f}\")\n",
    "                        print(f\"  * 75%: {stats['75%']:.2f}\")\n",
    "                        print(f\"  * Max: {stats['max']:.2f}\")\n",
    "                        \n",
    "                        # Vérification des valeurs négatives pour les distances\n",
    "                        if 'DISTANCE' in col and (X_train[col] < 0).any():\n",
    "                            print(\"⚠️ ATTENTION: Valeurs négatives détectées pour une distance!\")\n",
    "                        \n",
    "                        # Vérification des proportions\n",
    "                        if 'PROPORTION' in col:\n",
    "                            if (X_train[col] < 0).any() or (X_train[col] > 1).any():\n",
    "                                print(\"⚠️ ATTENTION: Proportions hors de l'intervalle [0,1]!\")\n",
    "                        \n",
    "                        median_val = stats['50%']\n",
    "                        X_train[col].fillna(median_val, inplace=True)\n",
    "                        X_test[col].fillna(median_val, inplace=True)\n",
    "                        print(f\"- Imputation avec la médiane: {median_val}\")\n",
    "                        \n",
    "                    else:\n",
    "                        # Pour les variables catégorielles\n",
    "                        # Extraire le nombre après '<=' ou '>='\n",
    "                        def extract_number(x):\n",
    "                            if pd.isna(x):\n",
    "                                return x\n",
    "                            try:\n",
    "                                if '<=' in str(x):\n",
    "                                    return float(str(x).split('<=')[1].strip())\n",
    "                                elif '>=' in str(x):\n",
    "                                    return float(str(x).split('>=')[1].strip())\n",
    "                                return float(x)\n",
    "                            except:\n",
    "                                return x\n",
    "                        \n",
    "                        print(\"- Conversion en numérique...\")\n",
    "                        X_train[col] = X_train[col].apply(extract_number)\n",
    "                        X_test[col] = X_test[col].apply(extract_number)\n",
    "                        \n",
    "                        # Imputation avec la médiane après conversion\n",
    "                        median_val = X_train[col].median()\n",
    "                        X_train[col].fillna(median_val, inplace=True)\n",
    "                        X_test[col].fillna(median_val, inplace=True)\n",
    "                        print(f\"- Imputation avec la médiane: {median_val}\")\n",
    "                        \n",
    "                else:\n",
    "                    print(\"- Colonne ignorée (>70% manquant)\")\n",
    "                \n",
    "                # Vérifications post-traitement\n",
    "                missing_after = X_train[col].isnull().sum()\n",
    "                if missing_after > 0:\n",
    "                    print(f\"⚠️ ATTENTION: {missing_after} valeurs manquantes restantes!\")\n",
    "    \n",
    "    return X_train, X_test, missing_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 9 : Traitement Demographic\n",
    "def handle_demographic_vars(X_train, X_test, missing_summary, demographic_cols):\n",
    "    \"\"\"\n",
    "    Traite les variables démographiques avec vérification détaillée des types et valeurs\n",
    "    \"\"\"\n",
    "    missing_indicators = {}\n",
    "    print(\"\\nTraitement des variables démographiques:\")\n",
    "    \n",
    "    # Regrouper les colonnes par type\n",
    "    household_cols = [col for col in demographic_cols if col.startswith('MEN')]\n",
    "    individual_cols = [col for col in demographic_cols if col.startswith('IND')]\n",
    "    housing_cols = [col for col in demographic_cols if col.startswith('LOG')]\n",
    "    \n",
    "    for col_type, cols in [\n",
    "        (\"Ménages\", household_cols),\n",
    "        (\"Individus\", individual_cols),\n",
    "        (\"Logements\", housing_cols)\n",
    "    ]:\n",
    "        print(f\"\\n=== Variables {col_type} ===\")\n",
    "        \n",
    "        for col in cols:\n",
    "            if col in X_train.columns:\n",
    "                missing_pct = missing_summary.loc[col, 'Missing Percentage']\n",
    "                print(f\"\\nColonne {col}:\")\n",
    "                print(f\"- Pourcentage de valeurs manquantes: {missing_pct:.2f}%\")\n",
    "                print(f\"- Type initial: {X_train[col].dtype}\")\n",
    "                \n",
    "                # Créer indicateur de valeurs manquantes\n",
    "                if missing_pct > 0:\n",
    "                    missing_indicators[f'{col}_is_missing'] = X_train[col].isnull().astype(int)\n",
    "                \n",
    "                if missing_pct <= 70:  # On traite uniquement si moins de 70% manquant\n",
    "                    if X_train[col].dtype in ['int64', 'float64']:\n",
    "                        # Pour les variables numériques\n",
    "                        stats = X_train[col].describe()\n",
    "                        print(\"- Statistiques descriptives:\")\n",
    "                        print(f\"  * Moyenne: {stats['mean']:.2f}\")\n",
    "                        print(f\"  * Écart-type: {stats['std']:.2f}\")\n",
    "                        print(f\"  * Min: {stats['min']:.2f}\")\n",
    "                        print(f\"  * 25%: {stats['25%']:.2f}\")\n",
    "                        print(f\"  * Médiane: {stats['50%']:.2f}\")\n",
    "                        print(f\"  * 75%: {stats['75%']:.2f}\")\n",
    "                        print(f\"  * Max: {stats['max']:.2f}\")\n",
    "                        \n",
    "                        # Vérifications spécifiques selon le type de variable\n",
    "                        if col.startswith('MEN') or col.startswith('IND'):\n",
    "                            if (X_train[col] < 0).any():\n",
    "                                print(\"⚠️ ATTENTION: Valeurs négatives détectées pour un comptage!\")\n",
    "                        \n",
    "                        # Vérification de la cohérence des proportions\n",
    "                        if 'PROP' in col or 'PAUV' in col:\n",
    "                            if (X_train[col] < 0).any() or (X_train[col] > 1).any():\n",
    "                                print(\"⚠️ ATTENTION: Proportions hors de l'intervalle [0,1]!\")\n",
    "                        \n",
    "                        median_val = stats['50%']\n",
    "                        X_train[col].fillna(median_val, inplace=True)\n",
    "                        X_test[col].fillna(median_val, inplace=True)\n",
    "                        print(f\"- Imputation avec la médiane: {median_val}\")\n",
    "                        \n",
    "                    else:\n",
    "                        # Pour les variables catégorielles\n",
    "                        value_counts = X_train[col].value_counts()\n",
    "                        print(\"- Distribution des valeurs:\")\n",
    "                        print(value_counts.head())\n",
    "                        print(f\"- Nombre total de catégories: {len(value_counts)}\")\n",
    "                        \n",
    "                        X_train[col].fillna('UNKNOWN', inplace=True)\n",
    "                        X_test[col].fillna('UNKNOWN', inplace=True)\n",
    "                        print(\"- Imputation avec 'UNKNOWN'\")\n",
    "                else:\n",
    "                    print(\"- Colonne ignorée (>70% manquant)\")\n",
    "                \n",
    "                # Vérifications post-traitement\n",
    "                missing_after = X_train[col].isnull().sum()\n",
    "                if missing_after > 0:\n",
    "                    print(f\"⚠️ ATTENTION: {missing_after} valeurs manquantes restantes!\")\n",
    "                \n",
    "                # Vérification de la cohérence des données\n",
    "                if col.startswith('MEN'):\n",
    "                    total_men = X_train['MEN'] if 'MEN' in X_train.columns else None\n",
    "                    if total_men is not None and col != 'MEN':\n",
    "                        if (X_train[col] > total_men).any():\n",
    "                            print(\"⚠️ ATTENTION: Sous-catégorie de ménages supérieure au total!\")\n",
    "                \n",
    "                if col.startswith('IND'):\n",
    "                    total_ind = X_train['IND'] if 'IND' in X_train.columns else None\n",
    "                    if total_ind is not None and col != 'IND':\n",
    "                        if (X_train[col] > total_ind).any():\n",
    "                            print(\"⚠️ ATTENTION: Sous-catégorie d'individus supérieure au total!\")\n",
    "    \n",
    "    return X_train, X_test, missing_indicators\n",
    "\n",
    "# Exécution\n",
    "X_train, X_test, demographic_indicators = handle_demographic_vars(\n",
    "    X_train, X_test, missing_summary, groups['Demographic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 10 : Finalisation\n",
    "def finalize_processing(X_train, X_test, all_indicators, missing_summary):\n",
    "    \"\"\"\n",
    "    Finalise le traitement des données avec vérifications détaillées\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Début de la finalisation ===\")\n",
    "    \n",
    "    # État initial\n",
    "    print(\"\\nÉtat initial:\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"Nombre d'indicateurs: {len(all_indicators)}\")\n",
    "    \n",
    "    # Vérification des index\n",
    "    print(\"\\nVérification des index:\")\n",
    "    print(f\"Index train unique: {X_train.index.is_unique}\")\n",
    "    print(f\"Index test unique: {X_test.index.is_unique}\")\n",
    "    \n",
    "    # Combiner les indicateurs\n",
    "    print(\"\\nCréation des DataFrames d'indicateurs...\")\n",
    "    indicators_df_train = pd.DataFrame(all_indicators, index=X_train.index)\n",
    "    indicators_df_test = pd.DataFrame(all_indicators, index=X_test.index)\n",
    "    \n",
    "    print(f\"Shape indicateurs train: {indicators_df_train.shape}\")\n",
    "    print(f\"Shape indicateurs test: {indicators_df_test.shape}\")\n",
    "    \n",
    "    # Concaténation\n",
    "    print(\"\\nConcaténation avec les données principales...\")\n",
    "    X_train = pd.concat([X_train, indicators_df_train], axis=1)\n",
    "    X_test = pd.concat([X_test, indicators_df_test], axis=1)\n",
    "    \n",
    "    # Suppression des colonnes avec beaucoup de valeurs manquantes\n",
    "    high_missing = missing_summary[missing_summary['Missing Percentage'] > 70].index\n",
    "    print(f\"\\nSuppression de {len(high_missing)} colonnes avec >70% de valeurs manquantes:\")\n",
    "    print(high_missing.tolist())\n",
    "    \n",
    "    X_train.drop(high_missing, axis=1, inplace=True)\n",
    "    X_test.drop(high_missing, axis=1, inplace=True)\n",
    "    \n",
    "    # Vérifications finales\n",
    "    print(\"\\n=== État final des données ===\")\n",
    "    print(f\"Shape après traitement:\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    \n",
    "    # Vérification des valeurs manquantes\n",
    "    final_missing_train = X_train.isnull().sum()\n",
    "    final_missing_test = X_test.isnull().sum()\n",
    "    \n",
    "    if final_missing_train.sum() > 0:\n",
    "        print(\"\\nColonnes avec valeurs manquantes restantes dans train:\")\n",
    "        print(final_missing_train[final_missing_train > 0])\n",
    "    else:\n",
    "        print(\"\\nAucune valeur manquante restante dans train\")\n",
    "        \n",
    "    if final_missing_test.sum() > 0:\n",
    "        print(\"\\nColonnes avec valeurs manquantes restantes dans test:\")\n",
    "        print(final_missing_test[final_missing_test > 0])\n",
    "    else:\n",
    "        print(\"\\nAucune valeur manquante restante dans test\")\n",
    "    \n",
    "    # Vérification des types de données\n",
    "    print(\"\\nTypes de données dans le jeu final:\")\n",
    "    print(X_train.dtypes.value_counts())\n",
    "    \n",
    "    # Vérification de la cohérence train/test\n",
    "    train_cols = set(X_train.columns)\n",
    "    test_cols = set(X_test.columns)\n",
    "    \n",
    "    if train_cols != test_cols:\n",
    "        print(\"\\n⚠️ ATTENTION: Différences dans les colonnes train/test!\")\n",
    "        print(\"Colonnes uniquement dans train:\", train_cols - test_cols)\n",
    "        print(\"Colonnes uniquement dans test:\", test_cols - train_cols)\n",
    "    else:\n",
    "        print(\"\\nColonnes cohérentes entre train et test\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "# Initialiser le dictionnaire des indicateurs\n",
    "all_indicators = {}\n",
    "\n",
    "# Liste des groupes d'indicateurs à vérifier\n",
    "indicator_groups = {\n",
    "    'weather': ('weather_indicators', weather_indicators if 'weather_indicators' in globals() else {}),\n",
    "    'building': ('building_indicators', building_indicators if 'building_indicators' in globals() else {}),\n",
    "    'activity': ('activity_indicators', activity_indicators if 'activity_indicators' in globals() else {}),\n",
    "    'insurance': ('insurance_indicators', insurance_indicators if 'insurance_indicators' in globals() else {}),\n",
    "    'geographic': ('geographic_indicators', geographic_indicators if 'geographic_indicators' in globals() else {}),\n",
    "    'demographic': ('demographic_indicators', demographic_indicators if 'demographic_indicators' in globals() else {})\n",
    "}\n",
    "\n",
    "# Ajouter chaque groupe d'indicateurs disponible\n",
    "for group_name, (var_name, indicators) in indicator_groups.items():\n",
    "    if indicators:\n",
    "        print(f\"Ajout de {len(indicators)} indicateurs du groupe {group_name}\")\n",
    "        all_indicators.update(indicators)\n",
    "    else:\n",
    "        print(f\"⚠️ Attention: Les indicateurs {group_name} sont manquants ou vides\")\n",
    "\n",
    "# Traitement final\n",
    "X_train_processed, X_test_processed = finalize_processing(\n",
    "    X_train, X_test, all_indicators, missing_summary\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
